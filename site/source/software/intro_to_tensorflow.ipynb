{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99d2f58-aa0c-48e8-9ffe-c0bd1fe9c737",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Computing with TensorFlow\n",
    "\n",
    "_Author_: Chris Jewell <c.jewell@lancaster.ac.uk>\n",
    "\n",
    "_Date_: 2022-03-22\n",
    "\n",
    "_Copyright_: Chris Jewell 2022\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc777246-b4e5-4f32-99da-23321845925c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "This notebook presents a brief introduction to using [TensorFlow](https://tensorflow.org) as a general compute engine for number crunching.  It is written very much from my experience of using the library to implement complex statistical models, and I'll try to highlight features of the library that lead to rapid implementation _and_ rapid runtime.\n",
    "\n",
    "This guide differs from most other guides and tutorials on [TensorFlow](https://tensorflow.org) by focusing on fundamental computing, such as vectorised and linear algebra, control flow, and automatic parallelisation.  I will _not_ cover use of the high-level machine learning functions provided by Keras, or the probabilistic programming language features provided by [TensorFlow Probability](https://tensorflow.org/probability). \n",
    "\n",
    "__Pre-requisites__:\n",
    "\n",
    "* Familiarity with Python\n",
    "* Familiarity with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec618b-03ae-4f9a-9169-92e687a87e87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What does TensorFlow do?\n",
    "\n",
    "From the [TensorFlow basics guide](https://www.tensorflow.org/guide/basics): \n",
    "\n",
    "> TensorFlow is an end-to-end platform for machine learning. It supports the following:\n",
    ">\n",
    "> * Multidimensional-array based numeric computation (similar to NumPy.)\n",
    "> * GPU and distributed processing\n",
    "> * Automatic differentiation\n",
    "> * Model construction, training, and export\n",
    "\n",
    "TensorFlow allows you to express your computation as a graph, leaving the hardware implementation to the library.  This leads to\n",
    "* rapid development\n",
    "* rapid computation\n",
    "* reduced bugs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbabfa-c296-4d66-8852-bb37b19a0a29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## TensorFlow library structure\n",
    "\n",
    "TensorFlow provides a rich set of [libraries](https://tensorflow.org/resources/libraries-extensions) that sit on top of the compute layer.  \n",
    "\n",
    "__NB__: Don't get confused, the Keras ML layer is part of TensorFlow core library!\n",
    "\n",
    "<div>\n",
    "<img src=\"https://gitlab.com/chrism0dwk/practical-epidemics/-/raw/master/site/source/notebooks/TF_diagram.png\" width=\"500\" alt=\"TensorFlow library organisation\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c236f1-6bac-44aa-8563-a2ec9bf93e67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Installing TensorFlow\n",
    "\n",
    "TensorFlow has bindings for a wide range of programming languages.  The Python API is most developed, so that is what we will use here.\n",
    "\n",
    "The latest release version (v2.8.0 as of 2022-03-22) of Tensorflow is best installed using `pip`\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```\n",
    "with bleeding-edge nightly development versions available too\n",
    "```bash\n",
    "pip install tf-nightly\n",
    "```\n",
    "\n",
    "__NB__. [Colab](https://colab.research.google.com) users already get TF installed in the standard instance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba78aa-2fdd-4316-b5cb-33badf2b0b21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Importing TensorFlow\n",
    "\n",
    "We can import TensorFlow in the usual Python way, and query the hardware devices available for TF to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe550de-5ebe-4e75-aff7-d571b1c96c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 13:08:03.402679: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-03-23 13:08:03.402708: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: diamond\n",
      "2022-03-23 13:08:03.402714: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: diamond\n",
      "2022-03-23 13:08:03.402758: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1\n",
      "2022-03-23 13:08:03.402774: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1\n",
      "2022-03-23 13:08:03.402778: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1\n",
      "2022-03-23 13:08:03.402989: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6685d-7a2b-4def-bf23-565ee6047605",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Tensors\n",
    "\n",
    "TensorFlow operators act on data stored as _Tensors_, which are\n",
    "* multidimensional arrays containing data _of the same type_\n",
    "* immutable -- you cannot directly modify them (see later!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911bed31-75ea-4095-ab5e-962eda240ac7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Skip just to hide library errors if GPU not found\n",
    "import tensorflow as tf\n",
    "x = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094b28f9-0be3-4756-88b9-b04ae287414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[1., 2., 3.],\n",
    "                 [4., 5., 6.]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65b432-9940-48be-a55c-06934d5e9a98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tensor properties\n",
    "\n",
    "Tensors have two _important_ properties similar to Numpy arrays:\n",
    "* `shape` gives the size of the Tensor along each axis\n",
    "* `dtype` gives the type of the data stored in the Tensor (float32, float64, int32, int64, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42613349-4e06-43f1-bee2-ac8048d727b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <dtype: 'float32'>\n",
      "Tensor shape: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type:\", x.dtype)\n",
    "print(\"Tensor shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfd592-1c03-4758-b93b-17d761d91e6e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Tensor operations\n",
    "\n",
    "Tensors may be subject to operations, similar to Numpy arrays.  e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b33134-a3da-4fc4-bfe4-de0f86955e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3., 4., 5.],\n",
       "       [6., 7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759d470a-9fcf-4795-9276-1348b26913cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 6., 12., 18.],\n",
       "       [24., 30., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f764357-420e-4b6f-9c7f-c8510bd7dcf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 4.],\n",
       "       [2., 5.],\n",
       "       [3., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615d05ec-df74-47da-a599-438492431669",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=21.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "068cbd4b-1ad7-4a82-b764-04c7ea96dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([5., 7., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(x, axis=0) # Reduce over dimension 0, i.e. colsums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669567e8-fcff-47ff-a537-ea48d7b4f9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 6., 15.], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(x, axis=1) # Reduce over dimension 1, i.e. rowsums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1afdd17-c866-4b22-8b50-0ca9ce9d24b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Shape manipulation\n",
    "\n",
    "Tensor shapes may be manipulated, remembering that elements in the _leftmost_ dimension are stored contiguously in memory.  Reshapes are a fast operation, as only array metadata needs to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ec17c0-0525-4f97-83fb-1ad6db47a9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x, shape=(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ad0d21-4238-4ec4-b422-47e6b21ed5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x, shape=-1) # special notation to `flatten` a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513df27f-ed45-47d0-bced-03e6b301615b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "and stacked or concatenated in the normal Numpy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12c8d6c-5113-44c2-bcb6-2a13dddf54cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.],\n",
       "       [ 7.,  8.,  9.],\n",
       "       [10., 11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.constant([[7., 8., 9.],\n",
    "                 [10., 11., 12.]])\n",
    "tf.concat([x, y], axis=0) # concatenate along first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2066f566-f3cd-43da-b218-08e662e2b7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
       "array([[[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.]],\n",
       "\n",
       "       [[ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([x, y], axis=0)  # Stack introduces a new dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c5ef3-801d-44fc-aa3a-f1350d4841fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Tensor `dtype`\n",
    "\n",
    "When computing with Tensors, `dtype` and `shape` is __everything__!  TensorFlow is _really_ fussy about `dtype` -- there is no automatic type promotion/demotion as in Numpy, R, C++, etc.!  \n",
    "\n",
    "Fortunately we can control `dtype` when we create a Tensor, such as the following 1-row matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa8c8f3c-8363-4810-b019-9579c902b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.constant([[13., 14., 15.]], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c16b13-9119-40d0-9fb5-53277bd6a068",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1278309/1295964305.py\", line 4, in <module>\n",
      "    tf.concat([x, z], axis=0)  # This fails as x.dtype == tf.float32 but z.dtype == tf.float64\n",
      "  File \"/home/jewellcp/Documents/Projects/practical-epidemics/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/jewellcp/Documents/Projects/practical-epidemics/.venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 7186, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute ConcatV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:ConcatV2] name: concat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback \n",
    "\n",
    "try:\n",
    "    tf.concat([x, z], axis=0)  # This fails as x.dtype == tf.float32 but z.dtype == tf.float64\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263232a-47d2-4538-9870-6e6f6b46d8ac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "This operation failed because `x.dtype == tf.float32` but `z.dtype == tf.float64`.  If needs be, we can cast Tensors to different `dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cf5bb08-fdc0-4947-bea4-ad2d1667c5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       "array([[ 1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.],\n",
       "       [13., 14., 15.]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([tf.cast(x, z.dtype),  # works, as we cast x to z's `dtype`\n",
    "           z],\n",
    "          axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d03df1-fff2-4dd3-84ee-0452aac1479f",
   "metadata": {},
   "source": [
    "though generally this should be avoided if possible as it hurts performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea52f1-fb76-4d00-a6c1-b7b7470d2c66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Tensor `shape`\n",
    "\n",
    "Tensor `shape` is equally important.  Shapes of binary operators must be _compatible_ -- they must obey [Numpy broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n",
    "\n",
    "For example this raises an `InvalidArgumentError`, because `x.shape = (2, 3)` is not compatible with `y.shape == (2,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6bf10e1-f702-493e-8d58-af9405952d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1278309/969305608.py\", line 5, in <module>\n",
      "    x * y\n",
      "  File \"/home/jewellcp/Documents/Projects/practical-epidemics/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/jewellcp/Documents/Projects/practical-epidemics/.venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 7186, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [2,3] vs. [2] [Op:Mul]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1., 2., 3.],\n",
    "                 [4., 5., 6.]])\n",
    "y = tf.constant([7., 8.])\n",
    "try:\n",
    "    x * y\n",
    "except tf.errors.InvalidArgumentError:\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8282765-db71-40c6-bcca-65b931f6b53d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Broadcasting\n",
    "\n",
    "But [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html) allows us to automatically operate on different shapes, provided the shapes broadcast together.  This allows some _incredibly_ concise code to express computations which in other languages would be more verbose.\n",
    "\n",
    "For example, I can calculate the outer product of two vectors by altering their shapes to 1-column and 1-row matrices respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b10fe0d-be5c-4e22-b6f9-977387034fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[ 0,  0,  0,  0,  0],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 12, 14, 16, 18],\n",
       "       [15, 18, 21, 24, 27],\n",
       "       [20, 24, 28, 32, 36]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(5)  # [0, 1, 2, 3, 4]\n",
    "b = tf.range(5, 10)  # [5, 6, 7, 8, 9]\n",
    "\n",
    "a[:, tf.newaxis] * b[tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc84fa-7c28-4f8a-9b87-197097a4e890",
   "metadata": {},
   "source": [
    "For more information, see the [TensorFlow basics guide](https://www.tensorflow.org/guide/tensor#about_shapes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83a53a-8bac-42af-b60d-7f5c048a846d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Indexing Tensors\n",
    "\n",
    "Indexing is an extensive topic, and readers are referred to the [TensorFlow Tensor Slicing Guide](https://www.tensorflow.org/guide/tensor_slicing) for an extensive discussion.\n",
    "\n",
    "Tensors may be indexed using Numpy-style integer or slice notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a81d0248-99f9-4450-874d-3f438aec3dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract x[2, 2] tf.Tensor(11.0, shape=(), dtype=float32)\n",
      "Extract row 1: tf.Tensor([5. 6. 7. 8.], shape=(4,), dtype=float32)\n",
      "Extract columns 2 and 3 tf.Tensor(\n",
      "[[ 3.  4.]\n",
      " [ 7.  8.]\n",
      " [11. 12.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1., 2., 3., 4.],\n",
    "                 [5., 6., 7., 8.],\n",
    "                 [9., 10., 11., 12.]])\n",
    "print(\"Extract x[2, 2]\", x[2, 2])\n",
    "print(\"Extract row 1:\", x[1, :])\n",
    "print(\"Extract columns 2 and 3\", x[:, 2:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be80e9a-a60d-44b7-9e60-83b57620b0c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "However, indexing using Tensors of indices will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "906e5ff9-c2af-43e8-ba38-bf8899d802d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1278309/201978485.py\", line 3, in <module>\n",
      "    x[:, col_idx]\n",
      "  File \"/home/jewellcp/Documents/Projects/practical-epidemics/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/jewellcp/Documents/Projects/practical-epidemics/.venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 899, in _check_index\n",
      "    raise TypeError(_SLICE_TYPE_ERROR + \", got {!r}\".format(idx))\n",
      "TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 2, 3], dtype=int32)>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_idx = tf.constant([0, 2, 3])\n",
    "try:\n",
    "    x[:, col_idx]\n",
    "except TypeError:\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288eea0-480c-47cd-9841-a1cc314404ef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### `tf.gather` and `tf.gather_nd`\n",
    "\n",
    "Instead of list indexing, we can use `tf.gather` to index on a single dimension, for example to extract columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4423c3d2-a31e-4241-91bc-cf59344e6993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  3.,  4.],\n",
       "       [ 5.,  7.,  8.],\n",
       "       [ 9., 11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(x, indices=col_idx, axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdeb258-8131-42d4-b523-b08a87d7bd9c",
   "metadata": {},
   "source": [
    "or to gather specific indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9d2b8a3-8e94-4218-ac27-feb9457f9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 2., 12.,  1.], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.constant([[0, 1], [2, 3], [0, 0]])\n",
    "tf.gather_nd(x, indices=indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d61767-528f-4d6c-8af4-fd781f00aff8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Updating Tensors\n",
    "\n",
    "Tensors are immutable -- we cannot assign to arbitrary elements like we can with Numpy.  So, for example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d66f7fd-b7ed-4967-a26b-2cbc2a3223d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x[2, 3] = 16.0\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb18d3-c24f-44e0-8f10-a979988465ae",
   "metadata": {},
   "source": [
    "raises a `TypeError`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84b6b5-13b9-40fd-aa6a-3a2ca6dce1f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Instead, however, we can use the `tf.tensor_scatter_nd_*` functions to add, subtract, or replace elements.  So our example should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd0acd0-e6fa-4b7f-ac94-cd8a608d0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = tf.tensor_scatter_nd_update(x, indices=[[2, 3]], updates=[16.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c67ef-7e47-48de-aad4-65557c829d5d",
   "metadata": {},
   "source": [
    "__NB__ `tf.tensor_scatter_nd_update` returns a new `new_x`, but wherever possible the memory belonging to the old `x` will be reused to avoid unnecessary copying of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908fcbb-ede9-4478-9ace-326a93d31dfa",
   "metadata": {},
   "source": [
    "## Converting between TensorFlow and Numpy\n",
    "\n",
    "TensorFlow allows conversion to and from Numpy arrays using `tf.convert_to_tensor` and `Tensor.numpy()` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60a65070-1196-4817-baa9-a5cc2664ba36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.78708352, -1.6118898 , -0.10471066],\n",
       "       [-3.53953039, -0.41078817, -0.5490035 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "foo = np.random.uniform(size=[2,3])\n",
    "\n",
    "foo_tf = tf.convert_to_tensor(foo)\n",
    "bar_tf = tf.math.log(foo_tf)\n",
    "\n",
    "bar_tf.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42814ba3-a0cb-4246-8409-eabc4d6c4daf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Computing gradients\n",
    "\n",
    "One of the most powerful features of Tensorflow is Autodiff.  Gradients may be calculated using the `tf.GradientTape` context manager.\n",
    "\n",
    "The Gradient Tape records the operations performed in a particular calculation, enabling [back-propagation](https://en.wikipedia.org/wiki/Backpropagation) auto-differentiation.\n",
    "\n",
    "For example, to record\n",
    "$$\\frac{\\mathrm{d} x^2}{\\mathrm{d} x} = 2x$$\n",
    "we first record the tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "972c4048-0570-4541-a32b-416cfc6ce577",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8d9b6-2f5c-4f1c-8386-0c444b698138",
   "metadata": {},
   "source": [
    "then use it to calculate our required gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53446914-f44c-4100-b1d6-369301a03695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(target=y, sources=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e2a39-62e4-4460-b45d-b5b9bada03d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Functions\n",
    "\n",
    "Tensors can be used -- and are encouraged to be used -- inside functions.  For example, let's calculate the pair-wise distance between all points in a set of 2D coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "271418c5-d7c1-4e22-a147-0e88614d38f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pairwise_distance(x_coords, y_coords):\n",
    "    x_coords = tf.convert_to_tensor(x_coords) # Good idea to ensure we have Tensors!\n",
    "    y_coords = tf.convert_to_tensor(y_coords)\n",
    "    dx = x_coords[:, tf.newaxis] - x_coords[tf.newaxis, :]\n",
    "    dy = y_coords[:, tf.newaxis] - y_coords[tf.newaxis, :]\n",
    "    return tf.sqrt(dx*dx + dy*dy)\n",
    "\n",
    "x_coords = tf.random.uniform(shape=[100])\n",
    "y_coords = tf.random.uniform(shape=[100])\n",
    "\n",
    "d = pairwise_distance(x_coords, y_coords)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0255a36-d111-4155-8b31-5ba19efc2da6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Loops\n",
    "\n",
    "Loops are implemented using the `tf.while_loop` operation.  This operation requires a _functional_ approach to programming, where we loop along a pre-specified tensor until a stopping criterion is met.\n",
    "\n",
    "We'll use `tf.while_loop` to implement an iterative Geometric random variable sampler.  A Geometric random variable represents the number of weighted coin tosses required to get the first heads up.  Our loop repeatedly tosses a weighted coin, accumulating the number of iterations until the coin comes up heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16ad4aa5-7aba-4232-ac87-ffaf77984eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=411>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = tf.constant(0.01)  # Probability of a heads up\n",
    "\n",
    "def loop_body(num_tosses, stop):  # loop_body takes same arguments as return values\n",
    "    u = tf.random.uniform(shape=[1])\n",
    "    must_stop = u < prob\n",
    "    return num_tosses+1, must_stop\n",
    "\n",
    "def loop_cond(num_tosses, stop):  # loop_condition returns False to break the loop\n",
    "    return tf.math.logical_not(stop)\n",
    "\n",
    "num_tosses, _ = tf.while_loop(cond=loop_cond, body=loop_body, loop_vars=(0, False))\n",
    "num_tosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1567dc6-8716-4a48-b813-1a046f4a879f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Conditionals\n",
    "\n",
    "Since TensorFlow is targeted at _vector_ processors, conditionals can seem a little weird.  However, really they are just following functional programming patterns.\n",
    "\n",
    "* `tf.cond`\n",
    "* `tf.switch_case`\n",
    "* `tf.where`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c597f-01df-41be-87a4-41ccaef3f4e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Selecting behaviour\n",
    "\n",
    "`tf.cond` allows selecting a behaviour based on a _scalar_ condition.  We define `true_fn` and `false_fn` functions, which take no arguments and return _exactly_ the `Tensorspec` (i.e. shape and dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47cb2b97-2874-4e27-b4ce-f037a99890e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def true_fn():\n",
    "    return tf.constant(1)\n",
    "\n",
    "def false_fn():\n",
    "    return tf.constant(0)\n",
    "\n",
    "tf.cond(tf.random.uniform(shape=[1]) < 0.5, true_fn, false_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832a795-0ad9-4a0a-9456-7c005d909df7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Selecting a function to run based on index\n",
    "\n",
    "`tf.switch_case` allows us to select a particular function from a list based on an enumeration (see also `tf.case`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "110408a3-74f3-4ab6-b33b-a1d5d00f373e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn0(): return tf.constant(0)\n",
    "def fn1(): return tf.constant(1)\n",
    "def fn2(): return tf.constant(2)\n",
    "\n",
    "branch_to_call = tf.constant(1)\n",
    "tf.switch_case(branch_to_call, branch_fns=(fn0, fn1, fn2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36077a-0d43-4106-95cd-b9cedba32998",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Selecting values from vectors\n",
    "\n",
    "`tf.where` allows us to select elements from one of two vectors depending on an element-wise criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3f05ea5-7b0d-4e06-867b-09fc67d03500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector: [False  True False  True]\n",
      "vals: [-1.  2. -3.  4.]\n"
     ]
    }
   ],
   "source": [
    "true_vals = tf.constant([1., 2., 3., 4.])\n",
    "false_vals = -true_vals\n",
    "\n",
    "selector = tf.random.uniform(shape=true_vals.shape) < 0.5\n",
    "vals = tf.where(selector, true_vals, false_vals)\n",
    "\n",
    "print(\"selector:\", selector.numpy())\n",
    "print(\"vals:\", vals.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e616d9-418b-47d8-b9c1-fd7dc87c4514",
   "metadata": {},
   "source": [
    "__NB__ a common pattern in vectorised programming is to compute *all* branches, and then use `tf.where` to select the relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3530d-afe6-4d42-a8a6-2d5ef473ec70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Graph mode\n",
    "\n",
    "So far, we have run all our code in \"Eager mode\" where all commands are run on the fly just like regular Numpy.  The real power of TensorFlow is when we run computations in \"Graph mode\".\n",
    "\n",
    "Graph mode is enabled by decorating our function with `@tf.function`, e.g. our Geometric function from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dad01d90-d70d-40b8-8ab8-a66451b2c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 13:08:04.660916: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 200000000 exceeds 10% of free system memory.\n",
      "2022-03-23 13:08:04.772051: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 200000000 exceeds 10% of free system memory.\n",
      "2022-03-23 13:08:04.884634: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 200000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def matrix_sq(x):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    return tf.linalg.matmul(x, x, transpose_a=True)\n",
    "\n",
    "x = np.random.uniform(size=(5000, 5000))\n",
    "z = matrix_sq(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099fba64-625f-46dd-9ad7-2205c9165e8c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Function tracing\n",
    "\n",
    "In Graph mode, operations within functions are first _traced_, and assembled into a directed acyclic graph.  Tracing only happens _once_ per function as long as its arguments stay the same.  \n",
    "\n",
    "This means that Python functions are (typically) only run during tracing, and are excluded when the compiled graph is run.  This is particularly true for `print` statements.  For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "933fb10c-01cf-4ce1-a4ef-31632dc5321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to  5\n",
      "First call: tf.Tensor(5, shape=(), dtype=int32)\n",
      "Second call: tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_one(x):\n",
    "    print(\"Adding to \", x)\n",
    "    return x\n",
    "\n",
    "print(\"First call:\",  add_one(5)) # Graph is traced, so `print` is called\n",
    "print(\"Second call:\", add_one(5)) # Graph already exists for this function, no tracing is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67695f-2b15-4858-a8d0-e97edfbb7b78",
   "metadata": {},
   "source": [
    "but if we change the argument, the function is re-traced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5b3fd01-275a-4c0e-98d8-729652533d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to  6\n",
      "Third call: tf.Tensor(6, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Third call:\", add_one(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0049e54-3129-464d-9dfc-52f7c00c9d86",
   "metadata": {},
   "source": [
    "To prevent re-tracing, we can specify the argument as a `tf.Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d57e9f40-7f45-44de-bc04-e97dee9e5839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to  Tensor(\"x:0\", shape=(), dtype=int32)\n",
      "Fourth call: tf.Tensor(7, shape=(), dtype=int32)\n",
      "Fifth call: tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fourth call:\", add_one(tf.constant(7)))  # tracing occurs\n",
    "print(\"Fifth call:\", add_one(tf.constant(8)))   # no tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ef284-ef22-4fe1-a133-e986553fa6dd",
   "metadata": {},
   "source": [
    "### Printing within a graph-mode function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddff887-bc81-4652-8169-76f3be9b047e",
   "metadata": {},
   "source": [
    "Notice that in \"Fourth call\" above, printing `x` (a Tensor) simply provides an empty `TensorSpec` with shape and `dtype` information but no actual value.  This is because `print` is only called during tracing _before_ the graph-mode function has been called with its actual value.  \n",
    "\n",
    "To print the actual value of a Tensor, use `tf.print` which is a TF operation and is compiled into the graph.  This can be useful for debugging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80a1db3d-e176-4784-8b76-55835f83a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to  9\n",
      "Sixth call: tf.Tensor(9, shape=(), dtype=int32)\n",
      "Adding to  10\n",
      "Seventh call: tf.Tensor(10, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_oneV2(x):\n",
    "    tf.print(\"Adding to \", x)\n",
    "    return x\n",
    "\n",
    "print(\"Sixth call:\", add_oneV2(tf.constant(9)))  # `tf.print` returns value of `x`\n",
    "print(\"Seventh call:\", add_oneV2(tf.constant(10))) # `tf.print` returns value of `x`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ac6bd-4782-46d5-90c5-458ad8d0c7f7",
   "metadata": {},
   "source": [
    "### Why graph mode\n",
    "\n",
    "Using graph mode, we give TensorFlow the opportunity to speed up our code by performing optimisations on our function, such as pre-computing constant values and fusing operations.  This is most effective on functions that require lots of smaller operations rather than one big one.  Therefore, we do not expect `tf.function` to accelerate a single call to, say, `tf.linalg.matmul`.\n",
    "\n",
    "__Limitations__:\n",
    "* Graph-compiled functions _must_ only return Tensors, or lists/tuples/dicts of Tensors!\n",
    "* For very short functions, graph compilation overhead may outweigh the computational gains.\n",
    "* Tracing is expensive: occasionally it is difficult to avoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eda123-7a06-42ed-a41a-1a6eb76695d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Just in time compilation\n",
    "\n",
    "TensorFlow provides a _just-in-time_ (JIT) compiler, [XLA](https://tensorflow.org/xla).  XLA provides an extreme level of optimisation, effectively compiling our Python code into low-level bytecode for rapid execution.  We can switch XLA on just as easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8c44ae7-372d-4b07-b12f-ae9755f55b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 13:08:07.281624: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 200000000 exceeds 10% of free system memory.\n",
      "2022-03-23 13:08:07.439877: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 200000000 exceeds 10% of free system memory.\n",
      "2022-03-23 13:08:07.525500: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55652302d260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-23 13:08:07.525519: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-23 13:08:07.532936: I tensorflow/compiler/jit/xla_compilation_cache.cc:399] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def matrix_sq(x):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    return tf.linalg.matmul(x, x, transpose_a=True)\n",
    "\n",
    "x = np.random.uniform(size=(5000, 5000))\n",
    "z = matrix_sq(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8be54f-f869-439d-8ee0-4140e789a748",
   "metadata": {},
   "source": [
    "### Limitations of XLA\n",
    "\n",
    "In addition to Graph-mode limitations, XLA has a number of further limitations:\n",
    "* the shapes of _all_ data structures must be known at compile time\n",
    "* XLA-compiled functions must be _pure_\n",
    "  * no side-effects, e.g. IO, printing, etc\n",
    "  \n",
    "Some TensorFlow operations are not available, e.g. `tf.sparse` operations, `tf.print`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e7a2b-4247-4175-9e48-be1607ab4fc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Worked example in epidemics\n",
    "\n",
    "To demonstrate the capabilities of TensorFlow in action, we'll use the example of a discrete-time \"SIR\" epidemic model simulation.  This simulation evolves the system through time, with Susceptible individuals transitioning to Infected, and Infected individuals transitioning to Removed.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://gitlab.com/chrism0dwk/practical-epidemics/-/raw/master/site/source/notebooks/sir_diagram.png\" width=\"500\" alt=\"TensorFlow library organisation\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d20ee7-60dc-4ce1-8b14-34202e76bde8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Given initial conditions $t=0$, $S_0 = 120000$, $I_0=1$, $R_0=0$, we can evolve the system discrete timesteps (of length 1) by\n",
    "\n",
    "1. Drawing new transition events\n",
    "$$y_{SI} \\sim Binomial(S_t, 1 - e^{-\\beta I_t}) \\\\ y_{IR} \\sim Binomial(I_t, 1 - e^{-\\gamma})$$\n",
    "\n",
    "2. Updating the states and time\n",
    "$$S_{t+1} = S_t - y_{SI} \\\\ I_{t+1} = I_t + y_{SE} - y_{IR} \\\\ R_{t+1} = R_{t}+ y_{IR} \\\\ t:=t+1$$\n",
    "\n",
    "3. Goto 1 while $t < 200$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c89311-2680-482e-8810-b63ddd095c52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## TensorFlow implementation\n",
    "\n",
    "To implement our simulation, we need to make use of vectorized operations and linear algebra where we can.  What follows is my personal preferred pattern for this problem!\n",
    "\n",
    "First define the state transition model and event rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a1813a1-3d7e-40bb-9e73-97a34999b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SIR model using stoichiometry matrix \n",
    "#                          SI  IR \n",
    "sir_stoich = tf.constant([[-1,  0],  # S\n",
    "                          [ 1, -1],  # I\n",
    "                          [ 0,  1]], # R\n",
    "                         dtype=np.float32)\n",
    "\n",
    "\n",
    "def make_transition_rate_fn(beta, gamma):  # Closures are a common pattern\n",
    "    \"\"\"S->I and I->R transitions\"\"\"\n",
    "    def fn(state):\n",
    "            return tf.stack([\n",
    "                    beta * state[1] / tf.reduce_sum(state),  # Infection rate\n",
    "                    gamma                                    # Recovery rate\n",
    "                ],\n",
    "                axis=0\n",
    "            )\n",
    "    return fn\n",
    "\n",
    "\n",
    "# Set initial state\n",
    "initial_state = np.array([120000, 1, 0], dtype=np.float32)\n",
    "\n",
    "# Set the parameters\n",
    "transition_rate_fn = make_transition_rate_fn(beta=0.3, gamma=0.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4966d3-0335-4e51-888a-1b925271f399",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now define the actual simulation loop, with random number seed propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fc45587-28d4-450e-aa17-9d95b0569c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability.python.internal import samplers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "def simulation(initial_state, transition_rate_fn, stoichiometry, num_steps, seed=0):\n",
    "    seed = samplers.sanitize_seed(seed)\n",
    "    \n",
    "    def one_step(seed_and_state, _):  # Timestep index is ignored\n",
    "        seed, state = seed_and_state\n",
    "        seed0, next_seed = samplers.split_seed(seed, salt=\"one_step\") # Split seed\n",
    "        \n",
    "        # Calculate transition probabilities\n",
    "        rates = transition_rate_fn(state)\n",
    "        probs = 1.0 - tf.math.exp(-rates)\n",
    "        \n",
    "        # Draw increments, batching together S->I and I->R\n",
    "        increments = tfd.Binomial(total_count=state[:2],  # Select (S, I), R is irrelevant\n",
    "                                  probs=probs).sample(seed=seed0)\n",
    "        \n",
    "        # Calculate new state\n",
    "        new_state = state + tf.linalg.matvec(stoichiometry, increments)\n",
    "        \n",
    "        return next_seed, new_state\n",
    "    \n",
    "    # tf.scan iteratively applies one_step (uses tf.while_loop)\n",
    "    _, simulation = tf.scan(fn=one_step,\n",
    "                            elems=tf.range(200),  # Run for 200 steps\n",
    "                            initializer=(seed, initial_state))\n",
    "    \n",
    "    return simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52b6e3-b0cf-4a8a-a7b4-221301a6cdf2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "and a plotting function for our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c50f1c87-ea3d-4d49-9828-c6653035cbae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sir(sim):\n",
    "    plt.plot(sim[:, 0], label=\"Susceptible\")\n",
    "    plt.plot(sim[:,1], label=\"Infected\")\n",
    "    plt.plot(sim[:, 2], label=\"Removed\")\n",
    "    plt.xlabel(\"Time/days\")\n",
    "    plt.ylabel(\"Number of individuals\")\n",
    "    plt.legend()\n",
    "    return None\n",
    "\n",
    "def time_this(fn):\n",
    "    \"\"\"Timing decorator using time.perf_counter\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        rv = fn(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(\"Elapsed wallclock time:\", end-start, \"seconds\")\n",
    "        return rv\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba08a5-faf5-4f0e-8bde-3008fb403a74",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Run the simulation in (default) Eager model, and plot the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5587dd6c-5bad-4960-9edf-60359a470275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed wallclock time: 0.7186074089840986 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "    \n",
    "@time_this\n",
    "def eager_mode():\n",
    "  return simulation(initial_state=initial_state, \n",
    "                    transition_rate_fn=transition_rate_fn,\n",
    "                    stoichiometry=sir_stoich,\n",
    "                    num_steps=200, \n",
    "                    seed=[4,2])\n",
    "sim = eager_mode()\n",
    "plot_sir(sim.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21719af-1969-4351-914f-a0e598b4a696",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Simulate in graph mode\n",
    "\n",
    "In graph mode, we get a speedup on the _second_ call to `simulate`.  This is because on the first call, we incur a graph compilation overhead.  However, with a compiled graph we get a 10x speedup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd6959b3-ce07-418a-97ef-274db4bae32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed wallclock time: 0.35742090101120993 seconds\n",
      "Elapsed wallclock time: 0.011307230975944549 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_this\n",
    "@tf.function\n",
    "def graph_mode():\n",
    "    return simulation(initial_state=initial_state, \n",
    "                      transition_rate_fn=transition_rate_fn,\n",
    "                      stoichiometry=sir_stoich,\n",
    "                      num_steps=200, \n",
    "                      seed=[2,2])\n",
    "\n",
    "sim = graph_mode()\n",
    "sim = graph_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0594861-8d31-4db4-be37-ff50c5381fa7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Simulate in XLA mode\n",
    "\n",
    "In XLA mode, we incur a large compilation overhead, but get an even faster function on the second call -- approximately a 500x speedup compared to Eager mode!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "159eecb6-ec19-4b01-8906-f6269e23016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 13:08:11.248248: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed wallclock time: 1.800255890993867 seconds\n",
      "Elapsed wallclock time: 0.0005566269974224269 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_this\n",
    "@tf.function(jit_compile=True)\n",
    "def xla_mode():\n",
    "    return simulation(initial_state=initial_state, \n",
    "                      transition_rate_fn=transition_rate_fn,\n",
    "                      stoichiometry=sir_stoich,\n",
    "                      num_steps=200, \n",
    "                      seed=[2,2])\n",
    "\n",
    "sim = xla_mode()\n",
    "sim = xla_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d72971-adaf-4a4d-863a-4116b7b5fb4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Remarks and conclusions\n",
    "\n",
    "For large computationally-intensive problems, TensorFlow provides an interesting framework for vectorised computation, autodiff, and hardware agnostic computing.  \n",
    "\n",
    "Graph mode and XLA mode are useful, _provided_:\n",
    "* Problem sizes are large\n",
    "* Problems are complex\n",
    "* Large graphs of operations are required\n",
    "\n",
    "Limitations in Graph mode and XLA require careful thought for some algorithms, however.  My advice is to try to replace conditionals (e.g. `np.where`, `if`/`else`, etc) with mathematical operations (e.g. multiply by 0 or 1) wherever possible.\n",
    "\n",
    "Decomposing problems in terms of _linear algebra_ leads to more concise code and (more often than not) improved runtime. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ef6f7-726b-4cac-a2ef-2f1e165b822b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Where next?\n",
    "I would recommend\n",
    "\n",
    "1. Reading the API docs at https://tensorflow.org/api_docs\n",
    "    * `tf.linalg`\n",
    "    * `tf.sparse`\n",
    "    * `tf.math`...\n",
    "\n",
    "2. Read the TensorFlow guide at https://tensorflow.org/guide\n",
    "\n",
    "3. Profiling with TensorBoard at https://www.tensorflow.org/tensorboard\n",
    "\n",
    "4. Machine learning library, `keras`, provides Neural Net building blocks\n",
    "\n",
    "5. [TensorFlow Probability](https://tensorflow.org/probability) provides probabilistic programming\n",
    "\n",
    "6. Let's open a discussion in the RSN Team!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
